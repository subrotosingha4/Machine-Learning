{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki2w--5_nlZO"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM58ggroqsQb"
      },
      "source": [
        "- CNN= Convolutional Layers+Fully Connected Layers\n",
        "- Convolutional layers=Feature Extractor\n",
        "- Fully Connected Layers= Classify Images\n",
        "- Train a CNN on image data,top layers learn to extract general features from images such as edges, distribution of colours, etc. \n",
        "- As we keep going deep in the network, the layers tend to extract more specific features.\n",
        "- we can use these pretrained models which already know how to extract features and avoid the training from scratch. This concept is known as transfer learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-V_ishFqq4A"
      },
      "source": [
        "# Transfer Learning using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1hyhT4jqj-8"
      },
      "source": [
        "- There are 2 ways to create models in Keras. One is the sequential model and the other is functional API. \n",
        "- The sequential model is a linear stack of layers. You can simply keep adding layers in a sequential model just by calling add method. \n",
        "- The other is functional API, which lets you create more complex models that might contain multiple input and output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw4aQpGnq_KZ"
      },
      "source": [
        "# VGG 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9CmzOWFq8Hp"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TDglvz1rLHn"
      },
      "source": [
        "## Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0S_FY0Fox3q",
        "outputId": "cca48b9d-2d20-40d1-b251-720bb9e7f6e8"
      },
      "source": [
        "import keras\n",
        "model=keras.models.Sequential()\n",
        "model.add(VGG16(weights='imagenet'))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 1000)              138357544 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0-e9SChr2pC"
      },
      "source": [
        "## Functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-31fqT9r5Jm",
        "outputId": "7202e24f-535d-4f37-e343-a327b3ee85c4"
      },
      "source": [
        "#input shape is the shape of an image in VGG16-224x224x3\n",
        "inp=keras.Input(shape=(224,224,3))\n",
        "out=VGG16(weights='imagenet')(inp)\n",
        "model=keras.Model(inputs=inp,outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, 1000)              138357544 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-c9opQOszfx"
      },
      "source": [
        "To use the pretrained weights we have to set the argument weights to imagenet. The default value is also set to imagenet. But if we want to train the model from scratch, we can set the **weights argument to None**. This will initialize the weights randomly in the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpVxd26ltBNA"
      },
      "source": [
        "# Attaching our own classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-n5rrsgtJP-"
      },
      "source": [
        "We can remove the default classifier and attach our own classifier in the pretrained model. To exclude the default classifier we have to set argument **include_top to false.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q28cvkuRtWRd"
      },
      "source": [
        "- In the following example, I am removing default classifier from VGG, then attaching my own classifier which is just one dense layer. We also have to include a flatten layer before adding a dense layer to convert the 4D output from the Convolution layer to 2D, since the dense layer accepts 2D input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e__J_8UPs1qe",
        "outputId": "b4e2828d-acb9-4e19-c8f5-0ea367a91d08"
      },
      "source": [
        "model1=keras.models.Sequential()\n",
        "model1.add(VGG16(include_top=False,input_shape=(224,224,3)))\n",
        "\n",
        "model1.add(keras.layers.Flatten())\n",
        "model1.add(keras.layers.Dense(10))\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                250890    \n",
            "=================================================================\n",
            "Total params: 14,965,578\n",
            "Trainable params: 14,965,578\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnNwv5ojuKuy"
      },
      "source": [
        "## Input Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_39POk4uQJS"
      },
      "source": [
        "- VGG16 is trained on RGB images of size (224, 224), which is a default input size of the network. We can also feed the input image other than the default size. But the height and width of the image should be more than 32 pixels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTjnS_0huL2_",
        "outputId": "8236d046-dfb4-4a72-d4e7-83d58ae7764a"
      },
      "source": [
        "model1=keras.models.Sequential()\n",
        "model1.add(VGG16(include_top=False,input_shape=(32,64,3)))\n",
        "\n",
        "model1.add(keras.layers.Flatten())\n",
        "model1.add(keras.layers.Dense(10))\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 1, 2, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 14,724,938\n",
            "Trainable params: 14,724,938\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq4i1zNmugjz"
      },
      "source": [
        "- We can also define input shape by providing input tensor as shown in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ic29Xqruhvq",
        "outputId": "b461bd73-bd17-4b44-a1cd-ede141465695"
      },
      "source": [
        "model=keras.models.Sequential()\n",
        "\n",
        "inpu=keras.Input(shape=(32,64,3))\n",
        "\n",
        "model.add(VGG16(include_top=False,input_tensor=inp))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq7fU4Td_tx7"
      },
      "source": [
        "#Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlPEBCaM_1Ta"
      },
      "source": [
        "- We can apply 2 types of pooling on the final output from Convolution Layers. global average pooling and global maximum pooling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHbeoUmtBUMQ"
      },
      "source": [
        "- Global pooling is useful when we have a variable size of input images. Suppose we have 2 different sizes of output tensor from different sizes of images. The shape of the output tensor is (3, 3, 512) and (7, 7, 512). After applying global pooling on any of these tensors will get us a fixed-size vector of length 512. So the final output of variable size images will still be a fixed size vector after applying global pooling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uZF1b_R_vms",
        "outputId": "e0a16be8-47f0-4254-f9a6-fc818f471c7d"
      },
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(VGG16(include_top=False,input_shape=(224,224,3),pooling='avg'))\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 512)               14714688  \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4e36YsBBa9K"
      },
      "source": [
        "#Freezing layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5n6FhfyBcUV",
        "outputId": "a0d95727-fa91-4197-dc22-7039ff832701"
      },
      "source": [
        "VGG= VGG16(include_top=False,input_shape=(224,224,3))\n",
        "\n",
        "for layer in VGG.layers[:10]:\n",
        "\tlayer.trainable=False\n",
        "\n",
        "for layer in VGG.layers:\n",
        "\tsp=' '[len(layer.name)-9:]\n",
        "\tprint(layer.name,sp,layer.trainable)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_10   False\n",
            "block1_conv1  False\n",
            "block1_conv2  False\n",
            "block1_pool  False\n",
            "block2_conv1  False\n",
            "block2_conv2  False\n",
            "block2_pool  False\n",
            "block3_conv1  False\n",
            "block3_conv2  False\n",
            "block3_conv3  False\n",
            "block3_pool  True\n",
            "block4_conv1  True\n",
            "block4_conv2  True\n",
            "block4_conv3  True\n",
            "block4_pool  True\n",
            "block5_conv1  True\n",
            "block5_conv2  True\n",
            "block5_conv3  True\n",
            "block5_pool  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogP4TbaUCfnG"
      },
      "source": [
        "- If the current dataset is similar to the dataset these networks were trained on, then its good to freeze all layers since images in both datasets would have similar features. But if the dataset if different then we should only freeze top layers and train bottom layers because top layers extract general features. More similar the dataset more layers we should freeze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG_0HvISClKU"
      },
      "source": [
        "# Using specific layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5FSxepVCsV2"
      },
      "source": [
        "- In the following example, I am adding the 3rd layer of pretrained model (block1_conv2) to a sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiN23Y9YCfLE",
        "outputId": "28343b20-25e4-40f5-8e9a-4b7aab80ff0a"
      },
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(64,kernel_size=3,input_shape=(224,224,3)))\n",
        "model.add(VGG16().layers[2])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 222, 222, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        multiple                  36928     \n",
            "=================================================================\n",
            "Total params: 38,720\n",
            "Trainable params: 38,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}